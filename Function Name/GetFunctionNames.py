#Python web parsing
#The purpose of this script is to navigate the M-AT wiki
#and build a list of the functions from the information there.
def main():
	import sys, re, collections, os, urllib.request

	#Declaration of permanent variables
	#Path to starting URL
	initial_url = "http://stxwiki.meditech.com"
	#the source variable contains the HTML source for the current URL
	source = ""

	#Open the page at the initial url and read the source code into source
	page = urllib.request.urlopen(initial_url+"/wiki11/Category:Functions")
	source = page.read()

	#convert page souce to plain text
	safe_source = str(source, encoding='cp1252', errors='ignore')
	page.close()

	#First, we need to setup the file that we will write data from the web to. This file
	#will then be used as input to the second script of this process, which will generate
	#the snippets. 

	#Output to the input file that will be used in the other script
	output_path = os.path.dirname(os.path.realpath(sys.argv[0]))+"\\functionNames.txt"

	#Empty the output file and print an opening line to the top of that file
	firstLine = "<!--- Text generated by python script. --->\n"
	file = open(output_path,'w')
	file.write(firstLine)
	file.close()

	#get the names of the functions
	names = re.findall("<li><a href=\"/wiki11/(@[a-zA-Z]+?)\" title",safe_source)
	
	output_array = []
	#For each name, write the name to an output string
	for name in names:
		print(name)
		output_array.append(name+"\n")
	output = "".join(output_array)

	#Re-open the file to append the data to the end of it. 
	file = open(output_path,'a')
	file.write(output)
	file.close()

